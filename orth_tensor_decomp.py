# -*- coding: utf-8 -*-
"""orth_tensor_decomp

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ju2LDRDW4VMxuP8fNbJ2BaX9zJV8Lltz

%%writefile Orth_Tensor.py
import numpy as np
def Orth_Tensor(U):
    matsize=np.shape(U)
    Dim=matsize[0]
    case1=[]
    for i in range(0, Dim):
        for j in range(0, Dim):
            for k in range(0, Dim):
                for l in range(0, Dim):
                    if (i == j == k == l):
                        case1.append((i,j,k,l))
    
    
    tensor_sum = np.zeros((Dim, Dim, Dim, Dim))
    for i in range(0, Dim):
      for j in range(0, Dim):
          for k in range(0, Dim):
              for l in range(0, Dim):
                  for each in case1:
                      tensor_sum[i,j,k,l] = tensor_sum[i,j,k,l] + U[i,each[0]]*U[j,each[1]]*U[k,each[2]]*U[l,each[3]];      
                      
    return tensor_sum
"""

execfile('Orth_Tensor.py')

"""Parameters and Initialization"""

import numpy as np
import matplotlib.pyplot as plt

eta_val=0.001
total_iter=20000
test_freq=100
batch_size=10
Dim=5
err_val=[]

index_val=[]

Randmat = np.random.rand(Dim,Dim)
UU, Lambda, VV = np.linalg.svd(Randmat, full_matrices=True)
A=np.copy(UU)

T=Orth_Tensor(A)
Randmat = np.random.rand(Dim,Dim)
UU, Lambda, VV = np.linalg.svd(Randmat, full_matrices=True)
U=np.copy(UU)
#print(U)

"""Start optimization"""

import matplotlib.pyplot as plt

import numpy as np
import matplotlib.pyplot as plt
def noisy_gradient_descent(batch_size,A,U,T):  
  err_val=[]
  index_val=[]
  #iter=0
  for iter in range(0,total_iter): 
      sum_gd=np.zeros([Dim,Dim]);
      for ind in range(0,batch_size):
          x_t=(np.random.random_integers(0,1,Dim)-0.5)*2;
          y_t=A.dot(x_t);
          for i in range(0,Dim):
              ui=np.copy(U[:,i])
              for j in range(0,Dim):
                  if (i!=j):
                      uj=np.copy(U[:,j]);
                      #tmp_gd=2*uj.dot(uj)*ui+ui.dot(uj)*uj-((uj.dot(y_t))**2)*(ui.dot(y_t))*y_t;
                      tmp_gd=uj.dot(uj)*ui+2*ui.dot(uj)*uj-((uj.dot(y_t))**2)*(ui.dot(y_t))*y_t;
                      sum_gd[:,i]=sum_gd[:,i]+tmp_gd;

      #print(U)      

      for i in range(0,Dim):
          u_i=np.copy(U[:,i]);
          gd=sum_gd[:,i]/batch_size
          #nt=
          u_i_p=u_i-eta_val*gd
          U[:,i]=u_i_p/np.sqrt(sum(np.power(u_i_p,2)))



      if (iter%test_freq)==0:
          #tmp_index=iter/test_freq;
          T_U=Orth_Tensor(U)
          diff_tensor=T-T_U
          #err_val[iter]=
          err_val.append(sum(sum(sum(sum(np.power( diff_tensor,2))))))
          index_val.append(iter)
#           print(iter)
#           print('-----')        
#           print(err_val)
#           print('-----')
#           print(U)
#           print('-----')
#           print(index_val)        
  return index_val,err_val

eta_val=0.001
total_iter=200
test_freq=100
batch_size=100
Dim=5

batch_size = (np.arange(10) +1)*100
batch_index_val, batch_err_val = [], []
for each in batch_size:
  Randmat = np.random.rand(Dim,Dim)
  UU, Lambda, VV = np.linalg.svd(Randmat, full_matrices=True)
  A=np.copy(UU)
  T=Orth_Tensor(A)
  Randmat = np.random.rand(Dim,Dim)
  UU, Lambda, VV = np.linalg.svd(Randmat, full_matrices=True)
  U=np.copy(UU)

  print("Batch Size: {0}".format(each))
  index_val, err_val = noisy_gradient_descent(each,A,U,T)
  batch_index_val.append(index_val)
  batch_err_val.append(err_val)
  print(err_val)
  plt.plot(index_val, err_val)
  plt.show()

